
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="" />

  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" type="text/css" href="/theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="/theme/pygments/github.min.css">
  <link rel="stylesheet" type="text/css" href="/theme/font-awesome/css/font-awesome.min.css">


    <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Satyanarayan Rao Atom">



<!-- Google Analytics -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-115635757-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->

<meta name="author" content="Satya" />
<meta name="description" content="I was really happy to read the chapter 1 of Bishop&#39;s Pattern Recognition book and realizing the relationship between L2-regularized MLR and Bayesian perspective. On page 30, he shows that if weights follow a gaussian distribution conditioned on selected hyper-parameter, then the maximum likelihood function would take the following form …" />
<meta name="keywords" content="">

<meta property="og:site_name" content="Satyanarayan Rao"/>
<meta property="og:title" content="Bayesian inference to L2-regularized MLR"/>
<meta property="og:description" content="I was really happy to read the chapter 1 of Bishop&#39;s Pattern Recognition book and realizing the relationship between L2-regularized MLR and Bayesian perspective. On page 30, he shows that if weights follow a gaussian distribution conditioned on selected hyper-parameter, then the maximum likelihood function would take the following form …"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="/bayesian-inference-to-l2-regularized-mlr.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2018-03-09 00:00:00+01:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="/author/satya.html">
<meta property="article:section" content="Concepts"/>
<meta property="og:image" content="">

  <title>Satyanarayan Rao &ndash; Bayesian inference to L2-regularized MLR</title>

</head>
<body>
  <aside>
    <div>
      <a href="">
        <img src="/theme/img/profile.png" alt="" title="">
      </a>
      <h1><a href=""></a></h1>


      <nav>
        <ul class="list">

          <li><a href="https://www.nature.com/nbt/articles?type=primer" target="_blank">Nature Primer Series</a></li>
        </ul>
      </nav>

      <ul class="social">
        <li><a class="sc-github" href="https://github.com/satyausc" target="_blank"><i class="fa fa-github"></i></a></li>
        <li><a class="sc-twitter" href="https://twitter.com/satyaiiitm" target="_blank"><i class="fa fa-twitter"></i></a></li>
        <li><a class="sc-favicon" href="#" target="_blank"><i class="fa fa-favicon"></i></a></li>
      </ul>
    </div>


  </aside>
  <main>

    <nav>
      <a href="">    Home
</a>

      <a href="/categories.html">Categories</a>

      <a href="/feeds/all.atom.xml">    Atom
</a>

    </nav>

<article class="single">
  <header>
      
    <h1 id="bayesian-inference-to-l2-regularized-mlr">Bayesian inference to L2-regularized MLR</h1>
    <p>
          Posted on Fri 09 March 2018 in <a href="/category/concepts.html">Concepts</a>


    </p>
  </header>


  <div>
    <p>I was really happy to read the chapter 1 of Bishop's Pattern Recognition book
and realizing the relationship between L2-regularized MLR and Bayesian
perspective. On <code>page 30</code>, he shows that if weights follow a
gaussian distribution conditioned on selected hyper-parameter, then the maximum likelihood function would take the following form: </p>
<p>$$ \frac{\beta}{2}\sum\limits_{n = 1}^{N} {y(x_{n}, \mathbf{w}) - t_{n}}^2 + \frac{\alpha}{2}\mathbf{w}^T\mathbf{w} $$</p>
<p>Which is similar to L2-regularized MLR with: </p>
<p>$$ \lambda = \frac{\alpha}{\beta}$$</p>
<p>NOTE: This finding was a result of healthy discussion with <a href="https://github.com/TsuPeiChiu">Tsu-Pei</a>.</p>
<p>A good question asked in this context was:</p>
<ul>
<li>Why do I need to bother about the distribution in cases where the length of weight vector $\mathbf{w}$ very small, for example, 5 or less than 10. </li>
</ul>
<p>And my response to this questions was: </p>
<ul>
<li>Well, probably there may not be any need of regularization in these type of cases. Ideally, we use regularization when we have considerable number of features. </li>
</ul>
  </div>
  <div class="tag-cloud">
    <p>
    </p>
  </div>





</article>

    <footer>
<p>&copy;  </p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p>    </footer>
  </main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Satyanarayan Rao ",
  "url" : "",
  "image": "",
  "description": ""
}
</script>

</body>
</html>